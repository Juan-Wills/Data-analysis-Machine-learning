{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56cc4c75",
   "metadata": {},
   "source": [
    "# NumPy Basics - Arrays and Vectorized Computation\n",
    "\n",
    "Welcome to Chapter 4! This notebook will guide you through the fundamental concepts of NumPy and vectorized programming. We'll explore how NumPy enables efficient array-based operations that form the foundation of data analysis in Python.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will master:\n",
    "- **Array-based operations** for data munging, cleaning, subsetting, filtering, and transforming\n",
    "- **Efficient descriptive statistics** and data aggregation techniques\n",
    "- **Common algorithms** like sorting, unique operations, and set operations\n",
    "- **Data alignment** and relational data manipulation for merging heterogeneous datasets\n",
    "- **Conditional logic** expressed as array expressions\n",
    "- **Group-wise data manipulation** techniques\n",
    "- **Vectorized programming** concepts and best practices\n",
    "\n",
    "Let's dive into the world of efficient numerical computing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26753d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"Setup complete! Ready to explore vectorized computation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677ff36",
   "metadata": {},
   "source": [
    "## 1. Array-Based Operations for Data Munging and Cleaning\n",
    "\n",
    "NumPy arrays enable vectorized operations that are both faster and more concise than traditional loops. Let's explore the fundamental operations for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05adb763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice array-based operations here\n",
    "# Create sample data for manipulation\n",
    "sample_data = np.array([1.5, 2.3, -1.2, 4.1, -0.8, 3.7, 2.9, -2.1, 1.8, 0.5])\n",
    "print(\"Sample data:\", sample_data)\n",
    "\n",
    "# Your array-based operations practice goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11acf6",
   "metadata": {},
   "source": [
    "## 2. Efficient Descriptive Statistics and Data Aggregation\n",
    "\n",
    "NumPy provides highly optimized functions for computing statistics and aggregating data across different axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice descriptive statistics here\n",
    "# Create multi-dimensional sample data\n",
    "stats_data = np.random.randn(5, 4)\n",
    "print(\"Sample 2D data:\")\n",
    "print(stats_data)\n",
    "\n",
    "# Your statistics and aggregation practice goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d849a5",
   "metadata": {},
   "source": [
    "## 3. Common Algorithms: Sorting, Unique, and Set Operations\n",
    "\n",
    "Explore NumPy's efficient implementations of common algorithms used in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice sorting, unique, and set operations here\n",
    "# Sample data for algorithm practice\n",
    "algo_data = np.array([5, 2, 8, 2, 9, 1, 5, 8, 3, 7, 2, 9])\n",
    "set_a = np.array([1, 2, 3, 4, 5])\n",
    "set_b = np.array([4, 5, 6, 7, 8])\n",
    "\n",
    "print(\"Algorithm practice data:\", algo_data)\n",
    "print(\"Set A:\", set_a)\n",
    "print(\"Set B:\", set_b)\n",
    "\n",
    "# Your algorithm practice goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb84280",
   "metadata": {},
   "source": [
    "## 4. Data Alignment and Relational Data Manipulation\n",
    "\n",
    "Learn how to merge and join heterogeneous datasets using NumPy's broadcasting and indexing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice data alignment and manipulation here\n",
    "# Sample datasets for alignment practice\n",
    "dataset_a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "dataset_b = np.array([10, 20, 30])\n",
    "indices = np.array([0, 2, 1])\n",
    "\n",
    "print(\"Dataset A:\")\n",
    "print(dataset_a)\n",
    "print(\"Dataset B:\", dataset_b)\n",
    "print(\"Indices:\", indices)\n",
    "\n",
    "# Your data alignment practice goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8444c5",
   "metadata": {},
   "source": [
    "## 5. Expressing Conditional Logic as Array Expressions\n",
    "\n",
    "Master the art of vectorized conditional operations using `np.where`, boolean indexing, and logical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4288596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice conditional logic here\n",
    "# Sample data for conditional operations\n",
    "condition_data = np.array([[-1.2, 2.3, -0.8], [1.5, -2.1, 3.7], [0.5, -1.8, 2.9]])\n",
    "threshold = 0.0\n",
    "\n",
    "print(\"Condition data:\")\n",
    "print(condition_data)\n",
    "print(f\"Threshold: {threshold}\")\n",
    "\n",
    "# Your conditional logic practice goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3f3c2",
   "metadata": {},
   "source": [
    "## 6. Group-wise Data Manipulation\n",
    "\n",
    "Explore techniques for performing operations on grouped data using advanced indexing and aggregation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice group-wise operations here\n",
    "# Sample grouped data\n",
    "values = np.array([10, 15, 20, 25, 30, 35, 40, 45])\n",
    "groups = np.array(['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B'])\n",
    "\n",
    "print(\"Values:\", values)\n",
    "print(\"Groups:\", groups)\n",
    "\n",
    "# Your group-wise manipulation practice goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec28a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ ULTIMATE CHALLENGE: Portfolio Risk Analysis with Monte Carlo Simulation\n",
    "\n",
    "Now that you've mastered the fundamentals of NumPy, it's time for your final challenge! This exercise combines all the concepts you've learned in a real-world financial application.\n",
    "\n",
    "## The Challenge: Multi-Asset Portfolio Risk Assessment\n",
    "\n",
    "You are a quantitative analyst tasked with analyzing the risk and return characteristics of a diversified investment portfolio using Monte Carlo simulation. This challenge will test your ability to work with vectorized operations, statistical analysis, and complex data manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a178bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREBUILT DATA FOR THE CHALLENGE\n",
    "# Do not modify this cell - use these arrays in your solution\n",
    "\n",
    "# Portfolio of 8 assets with their characteristics\n",
    "asset_names = np.array(['US_Stocks', 'EU_Stocks', 'Asia_Stocks', 'Bonds', \n",
    "                       'Real_Estate', 'Commodities', 'Crypto', 'Cash'])\n",
    "\n",
    "# Historical annual returns (mean) for each asset\n",
    "expected_returns = np.array([0.10, 0.08, 0.12, 0.04, 0.07, 0.06, 0.15, 0.02])\n",
    "\n",
    "# Historical volatility (standard deviation) for each asset\n",
    "volatilities = np.array([0.16, 0.18, 0.22, 0.05, 0.14, 0.24, 0.45, 0.01])\n",
    "\n",
    "# Correlation matrix (8x8) between assets\n",
    "correlation_matrix = np.array([\n",
    "    [1.00, 0.75, 0.65, -0.20, 0.60, 0.30, 0.15, -0.05],\n",
    "    [0.75, 1.00, 0.70, -0.15, 0.55, 0.25, 0.10, -0.03],\n",
    "    [0.65, 0.70, 1.00, -0.25, 0.50, 0.35, 0.20, -0.08],\n",
    "    [-0.20, -0.15, -0.25, 1.00, 0.10, -0.10, -0.05, 0.90],\n",
    "    [0.60, 0.55, 0.50, 0.10, 1.00, 0.40, 0.25, 0.05],\n",
    "    [0.30, 0.25, 0.35, -0.10, 0.40, 1.00, 0.30, -0.15],\n",
    "    [0.15, 0.10, 0.20, -0.05, 0.25, 0.30, 1.00, -0.20],\n",
    "    [-0.05, -0.03, -0.08, 0.90, 0.05, -0.15, -0.20, 1.00]\n",
    "])\n",
    "\n",
    "# Current portfolio weights (must sum to 1.0)\n",
    "portfolio_weights = np.array([0.25, 0.20, 0.15, 0.20, 0.10, 0.05, 0.03, 0.02])\n",
    "\n",
    "# Initial portfolio value\n",
    "initial_portfolio_value = 1000000  # $1 million\n",
    "\n",
    "# Simulation parameters\n",
    "num_simulations = 10000\n",
    "time_horizon = 252  # Trading days in a year\n",
    "num_scenarios = 5   # Different market scenarios to test\n",
    "\n",
    "print(\"üìä PORTFOLIO CHALLENGE DATA LOADED\")\n",
    "print(f\"Assets: {len(asset_names)}\")\n",
    "print(f\"Portfolio Value: ${initial_portfolio_value:,}\")\n",
    "print(f\"Simulations: {num_simulations:,}\")\n",
    "print(f\"Time Horizon: {time_horizon} days\")\n",
    "print(\"‚úÖ Ready for your challenge!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030c08f",
   "metadata": {},
   "source": [
    "## üéØ Your Mission: Complete These 10 Tasks\n",
    "\n",
    "### **Task 1: Covariance Matrix Construction**\n",
    "Using the correlation matrix and volatilities, construct the full covariance matrix for all assets. Remember: `Cov(i,j) = Corr(i,j) * Vol(i) * Vol(j)`\n",
    "\n",
    "### **Task 2: Portfolio Risk Metrics**\n",
    "Calculate the portfolio's expected annual return and risk (standard deviation) using matrix operations and the portfolio weights.\n",
    "\n",
    "### **Task 3: Monte Carlo Setup**\n",
    "Create a function that generates correlated random returns for all assets using the covariance matrix. Use `np.random.multivariate_normal()` for correlated sampling.\n",
    "\n",
    "### **Task 4: Single Simulation Path**\n",
    "Generate one complete simulation path showing daily portfolio values over the time horizon. Plot this path to visualize the portfolio's potential trajectory.\n",
    "\n",
    "### **Task 5: Full Monte Carlo Simulation**\n",
    "Run the complete Monte Carlo simulation with all 10,000 paths. Store the final portfolio values for analysis.\n",
    "\n",
    "### **Task 6: Risk Analysis**\n",
    "From your simulation results, calculate:\n",
    "- Value at Risk (VaR) at 95% and 99% confidence levels\n",
    "- Expected Shortfall (Conditional VaR)\n",
    "- Maximum Drawdown statistics\n",
    "- Probability of loss greater than 20%\n",
    "\n",
    "### **Task 7: Scenario Analysis**\n",
    "Create 5 different market scenarios by modifying the expected returns:\n",
    "1. **Bull Market**: Increase all equity returns by 50%\n",
    "2. **Bear Market**: Decrease all equity returns by 40%\n",
    "3. **High Inflation**: Increase commodity/real estate returns by 30%, decrease bonds by 20%\n",
    "4. **Economic Crisis**: Decrease all returns by 30%, increase correlations by 20%\n",
    "5. **Stagflation**: Flat equity returns, high commodity returns, negative bond returns\n",
    "\n",
    "Run simulations for each scenario and compare results.\n",
    "\n",
    "### **Task 8: Optimal Rebalancing**\n",
    "Implement a dynamic rebalancing strategy:\n",
    "- Every 21 days (monthly), check if any asset weight deviates by more than 2% from target\n",
    "- If yes, rebalance back to original weights\n",
    "- Compare performance with buy-and-hold strategy\n",
    "\n",
    "### **Task 9: Advanced Analytics**\n",
    "Create a comprehensive analysis including:\n",
    "- Rolling 30-day Sharpe ratios across all simulation paths\n",
    "- Asset contribution to portfolio risk (component VaR)\n",
    "- Efficient frontier analysis (test 3 different weight combinations)\n",
    "- Stress testing (what happens if worst-performing asset drops 50%?)\n",
    "\n",
    "### **Task 10: Visualization and Reporting**\n",
    "Create a professional dashboard with:\n",
    "- Histogram of final portfolio values\n",
    "- Time series plot of portfolio value percentiles (5th, 25th, 50th, 75th, 95th)\n",
    "- Risk decomposition by asset class\n",
    "- Scenario comparison table\n",
    "- Executive summary with key risk metrics\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Success Criteria\n",
    "Your solution should demonstrate mastery of:\n",
    "- ‚úÖ **Vectorized operations** instead of loops\n",
    "- ‚úÖ **Efficient statistical calculations** using NumPy functions\n",
    "- ‚úÖ **Advanced indexing and boolean operations**\n",
    "- ‚úÖ **Broadcasting and array manipulation**\n",
    "- ‚úÖ **Conditional logic with `np.where` and boolean masks**\n",
    "- ‚úÖ **Group-wise analysis and aggregations**\n",
    "- ‚úÖ **Memory-efficient handling of large arrays**\n",
    "\n",
    "## üí° Hints\n",
    "- Use `np.random.multivariate_normal()` for correlated random sampling\n",
    "- Leverage `np.percentile()` for VaR calculations  \n",
    "- Use `np.cumprod()` for cumulative returns\n",
    "- Apply `np.newaxis` for proper broadcasting\n",
    "- Utilize fancy indexing for rebalancing logic\n",
    "- Remember that daily returns should be `annual_return / 252`\n",
    "\n",
    "**Good luck, Quantitative Analyst! Show me your NumPy mastery! üöÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c621330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ YOUR SOLUTION WORKSPACE\n",
    "# Complete all 10 tasks below using NumPy's vectorized operations\n",
    "\n",
    "# Task 1: Covariance Matrix Construction\n",
    "# Your code here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Portfolio Risk Metrics\n",
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Monte Carlo Setup\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df246ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks 4-10: Continue your implementation here\n",
    "# Use additional cells as needed for each task\n",
    "# Remember to use vectorized operations and avoid loops!\n",
    "\n",
    "# Your complete solution goes here..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
